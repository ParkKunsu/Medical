{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b930b1",
   "metadata": {},
   "source": [
    "# CNN과 전이학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8e72b2",
   "metadata": {},
   "source": [
    "치매환자와 일반인의 뇌 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca3d2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'data-ch20' already exists and is not an empty directory.\n",
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18496</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,183,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18496\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m1,183,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,212,513</span> (4.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,212,513\u001b[0m (4.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,212,513</span> (4.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,212,513\u001b[0m (4.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunsu/miniconda3/envs/fast/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5371 - loss: 0.8388\n",
      "Epoch 1: val_loss improved from inf to 0.69180, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5349 - loss: 0.8332 - val_accuracy: 0.5750 - val_loss: 0.6918\n",
      "Epoch 2/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5644 - loss: 0.6923\n",
      "Epoch 2: val_loss improved from 0.69180 to 0.68493, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5664 - loss: 0.6921 - val_accuracy: 0.6583 - val_loss: 0.6849\n",
      "Epoch 3/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5191 - loss: 0.6918\n",
      "Epoch 3: val_loss did not improve from 0.68493\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5191 - loss: 0.6919 - val_accuracy: 0.5000 - val_loss: 0.6915\n",
      "Epoch 4/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4034 - loss: 0.7029\n",
      "Epoch 4: val_loss did not improve from 0.68493\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4061 - loss: 0.7026 - val_accuracy: 0.5000 - val_loss: 0.6898\n",
      "Epoch 5/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4931 - loss: 0.6956\n",
      "Epoch 5: val_loss did not improve from 0.68493\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4929 - loss: 0.6956 - val_accuracy: 0.5167 - val_loss: 0.6876\n",
      "Epoch 6/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5837 - loss: 0.6852\n",
      "Epoch 6: val_loss improved from 0.68493 to 0.67008, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5804 - loss: 0.6849 - val_accuracy: 0.5167 - val_loss: 0.6701\n",
      "Epoch 7/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5446 - loss: 0.6863\n",
      "Epoch 7: val_loss improved from 0.67008 to 0.64075, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5475 - loss: 0.6862 - val_accuracy: 0.6833 - val_loss: 0.6407\n",
      "Epoch 8/30\n",
      "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7010 - loss: 0.6463\n",
      "Epoch 8: val_loss improved from 0.64075 to 0.51026, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-2s\u001b[0m -57886us/step - accuracy: 0.6944 - loss: 0.6196 - val_accuracy: 0.8083 - val_loss: 0.5103\n",
      "Epoch 9/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7412 - loss: 0.5644\n",
      "Epoch 9: val_loss improved from 0.51026 to 0.47272, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7394 - loss: 0.5623 - val_accuracy: 0.8667 - val_loss: 0.4727\n",
      "Epoch 10/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7090 - loss: 0.5601\n",
      "Epoch 10: val_loss improved from 0.47272 to 0.27884, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7195 - loss: 0.5479 - val_accuracy: 0.9333 - val_loss: 0.2788\n",
      "Epoch 11/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9097 - loss: 0.2999\n",
      "Epoch 11: val_loss improved from 0.27884 to 0.16941, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9098 - loss: 0.2976 - val_accuracy: 0.9417 - val_loss: 0.1694\n",
      "Epoch 12/30\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9301 - loss: 0.1858\n",
      "Epoch 12: val_loss did not improve from 0.16941\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9306 - loss: 0.1859 - val_accuracy: 0.8583 - val_loss: 0.3656\n",
      "Epoch 13/30\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8858 - loss: 0.2958\n",
      "Epoch 13: val_loss improved from 0.16941 to 0.15273, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8878 - loss: 0.2929 - val_accuracy: 0.9417 - val_loss: 0.1527\n",
      "Epoch 14/30\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9117 - loss: 0.1946\n",
      "Epoch 14: val_loss improved from 0.15273 to 0.12475, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9133 - loss: 0.1931 - val_accuracy: 0.9417 - val_loss: 0.1248\n",
      "Epoch 15/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9449 - loss: 0.1263\n",
      "Epoch 15: val_loss did not improve from 0.12475\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9449 - loss: 0.1268 - val_accuracy: 0.9167 - val_loss: 0.2038\n",
      "Epoch 16/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9565 - loss: 0.1738\n",
      "Epoch 16: val_loss improved from 0.12475 to 0.09319, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9558 - loss: 0.1698 - val_accuracy: 0.9667 - val_loss: 0.0932\n",
      "Epoch 17/30\n",
      "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9683 - loss: 0.0971\n",
      "Epoch 17: val_loss did not improve from 0.09319\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9682 - loss: 0.0991 - val_accuracy: 0.9583 - val_loss: 0.1074\n",
      "Epoch 18/30\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9232 - loss: 0.2551\n",
      "Epoch 18: val_loss improved from 0.09319 to 0.07069, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9245 - loss: 0.2517 - val_accuracy: 0.9750 - val_loss: 0.0707\n",
      "Epoch 19/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9947 - loss: 0.0794\n",
      "Epoch 19: val_loss did not improve from 0.07069\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9930 - loss: 0.0850 - val_accuracy: 0.9667 - val_loss: 0.0788\n",
      "Epoch 20/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9538 - loss: 0.1445\n",
      "Epoch 20: val_loss did not improve from 0.07069\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9540 - loss: 0.1432 - val_accuracy: 0.9667 - val_loss: 0.0883\n",
      "Epoch 21/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9143 - loss: 0.1643\n",
      "Epoch 21: val_loss did not improve from 0.07069\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9152 - loss: 0.1630 - val_accuracy: 0.9500 - val_loss: 0.0916\n",
      "Epoch 22/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9840 - loss: 0.1032\n",
      "Epoch 22: val_loss did not improve from 0.07069\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9813 - loss: 0.1072 - val_accuracy: 0.9667 - val_loss: 0.0725\n",
      "Epoch 23/30\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9649 - loss: 0.0965\n",
      "Epoch 23: val_loss improved from 0.07069 to 0.05718, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9651 - loss: 0.0961 - val_accuracy: 0.9833 - val_loss: 0.0572\n",
      "Epoch 24/30\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9609 - loss: 0.1589\n",
      "Epoch 24: val_loss did not improve from 0.05718\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9618 - loss: 0.1555 - val_accuracy: 0.9750 - val_loss: 0.0667\n",
      "Epoch 25/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9499 - loss: 0.1075\n",
      "Epoch 25: val_loss improved from 0.05718 to 0.05134, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9513 - loss: 0.1077 - val_accuracy: 0.9750 - val_loss: 0.0513\n",
      "Epoch 26/30\n",
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9726 - loss: 0.0735\n",
      "Epoch 26: val_loss did not improve from 0.05134\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9716 - loss: 0.0752 - val_accuracy: 0.9667 - val_loss: 0.0575\n",
      "Epoch 27/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9639 - loss: 0.2582\n",
      "Epoch 27: val_loss did not improve from 0.05134\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9640 - loss: 0.2541 - val_accuracy: 0.9833 - val_loss: 0.0540\n",
      "Epoch 28/30\n",
      "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9771 - loss: 0.1002\n",
      "Epoch 28: val_loss did not improve from 0.05134\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9775 - loss: 0.0984 - val_accuracy: 0.9500 - val_loss: 0.1116\n",
      "Epoch 29/30\n",
      "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9429 - loss: 0.1342\n",
      "Epoch 29: val_loss did not improve from 0.05134\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9431 - loss: 0.1357 - val_accuracy: 0.9667 - val_loss: 0.0709\n",
      "Epoch 30/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9593 - loss: 0.1011\n",
      "Epoch 30: val_loss improved from 0.05134 to 0.04279, saving model to ./data-ch20/MNIST_CNN.keras\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9596 - loss: 0.1009 - val_accuracy: 0.9833 - val_loss: 0.0428\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9867 - loss: 0.0452\n",
      "\n",
      " Test Accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# !git clone https://github.com/taehojo/data-ch20.git\n",
    "\n",
    "# 학습셋의 변형을 설정\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # 픽셀의 값을 0.0~1.0사이로 정규화합니다.\n",
    "    horizontal_flip=True,  # 수평 대칭 이미지를 50% 확률로 만들어 추가합니다.\n",
    "    width_shift_range=0.1,  # 전체 크기의 10% 범위에서 좌우로 이동합니다.\n",
    "    height_shift_range=0.1,\n",
    ")  # 마찬가지로 위, 아래로 이동합니다.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"./data-ch20/train\", target_size=(150, 150), batch_size=5, class_mode=\"binary\"  # 학습셋이 있는 폴더의 위치\n",
    ")\n",
    "\n",
    "# 테스트셋은 이미지 부풀리기 과정을 진행하지 않음\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"./data-ch20/test\", target_size=(150, 150), batch_size=5, class_mode=\"binary\"  # 테스트셋이 있는 폴더의 위치\n",
    ")\n",
    "\n",
    "# 앞서 배운 CNN 모델을 만들어 적용\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(150, 150, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "# 모델의 실행 옵션을 설정\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# 모델 최적화를 위한 설정\n",
    "# modelpath = \"./data-ch20/MNIST_CNN.hdf5\"\n",
    "modelpath = \"./data-ch20/MNIST_CNN.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# 모델을 실행\n",
    "history = model.fit(train_generator, validation_data=test_generator, epochs=30, verbose=1, callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "# 테스트 정확도를 출력.\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(test_generator)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c179b5",
   "metadata": {},
   "source": [
    "# 전이학습 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "924506b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Epoch 1/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5459 - loss: 0.8407 - val_accuracy: 0.8000 - val_loss: 0.5265\n",
      "Epoch 2/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7158 - loss: 0.5399 - val_accuracy: 0.8000 - val_loss: 0.4827\n",
      "Epoch 3/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.8377 - loss: 0.4372 - val_accuracy: 0.9600 - val_loss: 0.3193\n",
      "Epoch 4/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.8589 - loss: 0.3761 - val_accuracy: 0.9000 - val_loss: 0.2888\n",
      "Epoch 5/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.8526 - loss: 0.3345 - val_accuracy: 0.8400 - val_loss: 0.3790\n",
      "Epoch 6/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.8768 - loss: 0.2970 - val_accuracy: 0.7200 - val_loss: 0.5285\n",
      "Epoch 7/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.7511 - loss: 0.4737 - val_accuracy: 0.9200 - val_loss: 0.1889\n",
      "Epoch 8/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m -7454us/step - accuracy: 0.8673 - loss: 0.2396 - val_accuracy: 0.8600 - val_loss: 0.2446\n",
      "Epoch 9/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.8806 - loss: 0.2654 - val_accuracy: 0.9200 - val_loss: 0.2202\n",
      "Epoch 10/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9253 - loss: 0.1848 - val_accuracy: 0.9800 - val_loss: 0.0964\n",
      "Epoch 11/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9421 - loss: 0.1816 - val_accuracy: 0.8800 - val_loss: 0.2749\n",
      "Epoch 12/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9207 - loss: 0.2062 - val_accuracy: 0.9800 - val_loss: 0.1056\n",
      "Epoch 13/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9403 - loss: 0.1444 - val_accuracy: 0.8800 - val_loss: 0.2172\n",
      "Epoch 14/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9247 - loss: 0.1919 - val_accuracy: 0.8400 - val_loss: 0.3713\n",
      "Epoch 15/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9123 - loss: 0.2786 - val_accuracy: 0.9800 - val_loss: 0.0843\n",
      "Epoch 16/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.8572 - loss: 0.2117 - val_accuracy: 0.9400 - val_loss: 0.1149\n",
      "Epoch 17/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9478 - loss: 0.2008 - val_accuracy: 0.9400 - val_loss: 0.1980\n",
      "Epoch 18/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9666 - loss: 0.1500 - val_accuracy: 0.9600 - val_loss: 0.0804\n",
      "Epoch 19/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9356 - loss: 0.1730 - val_accuracy: 0.9800 - val_loss: 0.1139\n",
      "Epoch 20/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9076 - loss: 0.2194 - val_accuracy: 0.9400 - val_loss: 0.1524\n",
      "Epoch 21/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9251 - loss: 0.1738 - val_accuracy: 0.9400 - val_loss: 0.1265\n",
      "Epoch 22/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-0s\u001b[0m 72ms/step - accuracy: 0.9041 - loss: 0.1812 - val_accuracy: 0.9800 - val_loss: 0.1101\n",
      "Epoch 23/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9518 - loss: 0.1260 - val_accuracy: 0.9200 - val_loss: 0.0968\n",
      "Epoch 24/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9052 - loss: 0.1797 - val_accuracy: 0.9600 - val_loss: 0.0974\n",
      "Epoch 25/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9108 - loss: 0.1405 - val_accuracy: 0.9600 - val_loss: 0.1215\n",
      "Epoch 26/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9216 - loss: 0.1706 - val_accuracy: 0.9800 - val_loss: 0.0580\n",
      "Epoch 27/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9448 - loss: 0.1600 - val_accuracy: 0.9600 - val_loss: 0.0724\n",
      "Epoch 28/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.8903 - loss: 0.1786 - val_accuracy: 0.9400 - val_loss: 0.1145\n",
      "Epoch 29/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9416 - loss: 0.1390 - val_accuracy: 1.0000 - val_loss: 0.0497\n",
      "Epoch 30/30\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9146 - loss: 0.1606 - val_accuracy: 0.9200 - val_loss: 0.1550\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9705 - loss: 0.0997\n",
      "\n",
      " Test Accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers, optimizers, callbacks\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습셋의 변형을 설정\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # 주어진 이미지의 크기를 설정\n",
    "    horizontal_flip=True,  # 수평 대칭 이미지를 50% 확률로 만들어 추가\n",
    "    width_shift_range=0.1,  # 전체 크기의 10% 범위에서 좌우로 이동\n",
    "    height_shift_range=0.1,\n",
    ")  # 마찬가지로 위, 아래로 이동\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\"./data-ch20/train\", target_size=(150, 150), batch_size=5, class_mode=\"binary\")\n",
    "\n",
    "# 테스트셋의 정규화를 설정\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\"./data-ch20/test\", target_size=(150, 150), batch_size=5, class_mode=\"binary\")\n",
    "\n",
    "# VGG16 모델을 로드\n",
    "transfer_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))\n",
    "transfer_model.trainable = False\n",
    "\n",
    "# 자체 모델을 설정\n",
    "finetune_model = models.Sequential()\n",
    "finetune_model.add(transfer_model)\n",
    "finetune_model.add(Flatten())\n",
    "finetune_model.add(Dense(64, activation=\"relu\"))\n",
    "finetune_model.add(Dropout(0.5))\n",
    "finetune_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# 모델의 실행 옵션을 설정\n",
    "finetune_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# 학습의 조기 중단을 설정\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "# 모델을 실행\n",
    "history = finetune_model.fit(train_generator, epochs=30, validation_data=test_generator, validation_steps=10, callbacks=[early_stopping_callback])\n",
    "\n",
    "# 테스트 정확도를 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" % (finetune_model.evaluate(test_generator)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207b741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
