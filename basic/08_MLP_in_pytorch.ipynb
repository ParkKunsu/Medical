{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46eefff",
   "metadata": {},
   "source": [
    "# iris 데이터로 mlp 실습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43d0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "dataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2653fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor(dataset.data, dtype=torch.float32)\n",
    "y = torch.tensor(dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d7433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# mlp 정의\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_units):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1365e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b0b66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad4da285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / Loss: 1.5926581621170044\n",
      "Epoch: 1 / Loss: 1.2069424390792847\n",
      "Epoch: 2 / Loss: 1.1153168678283691\n",
      "Epoch: 3 / Loss: 1.0769577026367188\n",
      "Epoch: 4 / Loss: 1.0271769762039185\n",
      "Epoch: 5 / Loss: 1.0050177574157715\n",
      "Epoch: 6 / Loss: 0.9722355008125305\n",
      "Epoch: 7 / Loss: 0.9463660717010498\n",
      "Epoch: 8 / Loss: 0.9192782640457153\n",
      "Epoch: 9 / Loss: 0.8943856954574585\n",
      "Epoch: 10 / Loss: 0.8700024485588074\n",
      "Epoch: 11 / Loss: 0.8445824980735779\n",
      "Epoch: 12 / Loss: 0.8209953904151917\n",
      "Epoch: 13 / Loss: 0.7962988615036011\n",
      "Epoch: 14 / Loss: 0.7729608416557312\n",
      "Epoch: 15 / Loss: 0.7493183612823486\n",
      "Epoch: 16 / Loss: 0.7257833480834961\n",
      "Epoch: 17 / Loss: 0.7006223797798157\n",
      "Epoch: 18 / Loss: 0.6749260425567627\n",
      "Epoch: 19 / Loss: 0.6543883085250854\n",
      "Epoch: 20 / Loss: 0.6358001232147217\n",
      "Epoch: 21 / Loss: 0.6185774803161621\n",
      "Epoch: 22 / Loss: 0.6024522185325623\n",
      "Epoch: 23 / Loss: 0.5874244570732117\n",
      "Epoch: 24 / Loss: 0.5734343528747559\n",
      "Epoch: 25 / Loss: 0.5602549314498901\n",
      "Epoch: 26 / Loss: 0.5480413436889648\n",
      "Epoch: 27 / Loss: 0.5365193486213684\n",
      "Epoch: 28 / Loss: 0.5257816910743713\n",
      "Epoch: 29 / Loss: 0.5156891942024231\n",
      "Epoch: 30 / Loss: 0.5061774849891663\n",
      "Epoch: 31 / Loss: 0.4971950352191925\n",
      "Epoch: 32 / Loss: 0.48867717385292053\n",
      "Epoch: 33 / Loss: 0.4805655777454376\n",
      "Epoch: 34 / Loss: 0.4728178381919861\n",
      "Epoch: 35 / Loss: 0.4653991162776947\n",
      "Epoch: 36 / Loss: 0.45827874541282654\n",
      "Epoch: 37 / Loss: 0.4514209032058716\n",
      "Epoch: 38 / Loss: 0.44485214352607727\n",
      "Epoch: 39 / Loss: 0.43850383162498474\n",
      "Epoch: 40 / Loss: 0.4323764145374298\n",
      "Epoch: 41 / Loss: 0.4264327585697174\n",
      "Epoch: 42 / Loss: 0.4207321107387543\n",
      "Epoch: 43 / Loss: 0.4151439666748047\n",
      "Epoch: 44 / Loss: 0.4097321629524231\n",
      "Epoch: 45 / Loss: 0.4044599235057831\n",
      "Epoch: 46 / Loss: 0.3992842435836792\n",
      "Epoch: 47 / Loss: 0.39429348707199097\n",
      "Epoch: 48 / Loss: 0.38962891697883606\n",
      "Epoch: 49 / Loss: 0.3851258456707001\n",
      "Epoch: 50 / Loss: 0.3810897171497345\n",
      "Epoch: 51 / Loss: 0.37748587131500244\n",
      "Epoch: 52 / Loss: 0.37518173456192017\n",
      "Epoch: 53 / Loss: 0.3735111653804779\n",
      "Epoch: 54 / Loss: 0.3751823306083679\n",
      "Epoch: 55 / Loss: 0.37934163212776184\n",
      "Epoch: 56 / Loss: 0.3915136158466339\n",
      "Epoch: 57 / Loss: 0.406943678855896\n",
      "Epoch: 58 / Loss: 0.44251149892807007\n",
      "Epoch: 59 / Loss: 0.45421478152275085\n",
      "Epoch: 60 / Loss: 0.5006203055381775\n",
      "Epoch: 61 / Loss: 0.4693972170352936\n",
      "Epoch: 62 / Loss: 0.4978916347026825\n",
      "Epoch: 63 / Loss: 0.44372156262397766\n",
      "Epoch: 64 / Loss: 0.4631653428077698\n",
      "Epoch: 65 / Loss: 0.4183141887187958\n",
      "Epoch: 66 / Loss: 0.4358489513397217\n",
      "Epoch: 67 / Loss: 0.4019470512866974\n",
      "Epoch: 68 / Loss: 0.4186099171638489\n",
      "Epoch: 69 / Loss: 0.3959663510322571\n",
      "Epoch: 70 / Loss: 0.41353681683540344\n",
      "Epoch: 71 / Loss: 0.3917538523674011\n",
      "Epoch: 72 / Loss: 0.41282689571380615\n",
      "Epoch: 73 / Loss: 0.39071664214134216\n",
      "Epoch: 74 / Loss: 0.41352003812789917\n",
      "Epoch: 75 / Loss: 0.39043480157852173\n",
      "Epoch: 76 / Loss: 0.41539883613586426\n",
      "Epoch: 77 / Loss: 0.3902169167995453\n",
      "Epoch: 78 / Loss: 0.41602998971939087\n",
      "Epoch: 79 / Loss: 0.3878478407859802\n",
      "Epoch: 80 / Loss: 0.4140731990337372\n",
      "Epoch: 81 / Loss: 0.38410767912864685\n",
      "Epoch: 82 / Loss: 0.4106992483139038\n",
      "Epoch: 83 / Loss: 0.3799636960029602\n",
      "Epoch: 84 / Loss: 0.4070577919483185\n",
      "Epoch: 85 / Loss: 0.37601569294929504\n",
      "Epoch: 86 / Loss: 0.4037627577781677\n",
      "Epoch: 87 / Loss: 0.3724575936794281\n",
      "Epoch: 88 / Loss: 0.40095070004463196\n",
      "Epoch: 89 / Loss: 0.3692381680011749\n",
      "Epoch: 90 / Loss: 0.3985050320625305\n",
      "Epoch: 91 / Loss: 0.3662228286266327\n",
      "Epoch: 92 / Loss: 0.3962448835372925\n",
      "Epoch: 93 / Loss: 0.36329248547554016\n",
      "Epoch: 94 / Loss: 0.3940303921699524\n",
      "Epoch: 95 / Loss: 0.3603809177875519\n",
      "Epoch: 96 / Loss: 0.3922531306743622\n",
      "Epoch: 97 / Loss: 0.3576946258544922\n",
      "Epoch: 98 / Loss: 0.39023903012275696\n",
      "Epoch: 99 / Loss: 0.35485216975212097\n"
     ]
    }
   ],
   "source": [
    "def train(model, optimizer, criterion):\n",
    "    for epoch in range(100):\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(f\"Epoch: {epoch} / Loss: {loss}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "train(model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d972ac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / Loss: 1.3506039381027222\n",
      "Epoch: 1 / Loss: 4.319884777069092\n",
      "Epoch: 2 / Loss: 5.39194393157959\n",
      "Epoch: 3 / Loss: 7.209568500518799\n",
      "Epoch: 4 / Loss: 1.9101585149765015\n",
      "Epoch: 5 / Loss: 1.834107518196106\n",
      "Epoch: 6 / Loss: 0.6778333187103271\n",
      "Epoch: 7 / Loss: 0.5731140971183777\n",
      "Epoch: 8 / Loss: 0.6644673347473145\n",
      "Epoch: 9 / Loss: 0.8085446953773499\n",
      "Epoch: 10 / Loss: 0.6347835659980774\n",
      "Epoch: 11 / Loss: 0.6368470788002014\n",
      "Epoch: 12 / Loss: 0.530325174331665\n",
      "Epoch: 13 / Loss: 0.5172183513641357\n",
      "Epoch: 14 / Loss: 0.46943482756614685\n",
      "Epoch: 15 / Loss: 0.45923030376434326\n",
      "Epoch: 16 / Loss: 0.4329557418823242\n",
      "Epoch: 17 / Loss: 0.42663782835006714\n",
      "Epoch: 18 / Loss: 0.4096251130104065\n",
      "Epoch: 19 / Loss: 0.40610283613204956\n",
      "Epoch: 20 / Loss: 0.3938947021961212\n",
      "Epoch: 21 / Loss: 0.393119752407074\n",
      "Epoch: 22 / Loss: 0.3836686611175537\n",
      "Epoch: 23 / Loss: 0.38598474860191345\n",
      "Epoch: 24 / Loss: 0.3780919909477234\n",
      "Epoch: 25 / Loss: 0.3839995563030243\n",
      "Epoch: 26 / Loss: 0.3760203719139099\n",
      "Epoch: 27 / Loss: 0.3851277530193329\n",
      "Epoch: 28 / Loss: 0.37549659609794617\n",
      "Epoch: 29 / Loss: 0.3866317570209503\n",
      "Epoch: 30 / Loss: 0.37365972995758057\n",
      "Epoch: 31 / Loss: 0.3856048583984375\n",
      "Epoch: 32 / Loss: 0.36924487352371216\n",
      "Epoch: 33 / Loss: 0.3806549310684204\n",
      "Epoch: 34 / Loss: 0.3624405264854431\n",
      "Epoch: 35 / Loss: 0.3734925389289856\n",
      "Epoch: 36 / Loss: 0.3549245595932007\n",
      "Epoch: 37 / Loss: 0.3660493791103363\n",
      "Epoch: 38 / Loss: 0.3477592170238495\n",
      "Epoch: 39 / Loss: 0.3590858280658722\n",
      "Epoch: 40 / Loss: 0.3416616916656494\n",
      "Epoch: 41 / Loss: 0.3536459803581238\n",
      "Epoch: 42 / Loss: 0.3366939127445221\n",
      "Epoch: 43 / Loss: 0.34962549805641174\n",
      "Epoch: 44 / Loss: 0.33271196484565735\n",
      "Epoch: 45 / Loss: 0.3467339873313904\n",
      "Epoch: 46 / Loss: 0.32936033606529236\n",
      "Epoch: 47 / Loss: 0.3442615866661072\n",
      "Epoch: 48 / Loss: 0.32613664865493774\n",
      "Epoch: 49 / Loss: 0.34188491106033325\n",
      "Epoch: 50 / Loss: 0.32307595014572144\n",
      "Epoch: 51 / Loss: 0.33923280239105225\n",
      "Epoch: 52 / Loss: 0.3197391927242279\n",
      "Epoch: 53 / Loss: 0.3364031910896301\n",
      "Epoch: 54 / Loss: 0.3165634274482727\n",
      "Epoch: 55 / Loss: 0.33414068818092346\n",
      "Epoch: 56 / Loss: 0.3137001693248749\n",
      "Epoch: 57 / Loss: 0.33151403069496155\n",
      "Epoch: 58 / Loss: 0.3106699287891388\n",
      "Epoch: 59 / Loss: 0.3288283348083496\n",
      "Epoch: 60 / Loss: 0.3077484369277954\n",
      "Epoch: 61 / Loss: 0.3263394236564636\n",
      "Epoch: 62 / Loss: 0.3048112690448761\n",
      "Epoch: 63 / Loss: 0.3237036466598511\n",
      "Epoch: 64 / Loss: 0.3019566237926483\n",
      "Epoch: 65 / Loss: 0.3209759593009949\n",
      "Epoch: 66 / Loss: 0.29893168807029724\n",
      "Epoch: 67 / Loss: 0.31848815083503723\n",
      "Epoch: 68 / Loss: 0.29642143845558167\n",
      "Epoch: 69 / Loss: 0.3163943588733673\n",
      "Epoch: 70 / Loss: 0.29399755597114563\n",
      "Epoch: 71 / Loss: 0.31401336193084717\n",
      "Epoch: 72 / Loss: 0.2912720739841461\n",
      "Epoch: 73 / Loss: 0.31148362159729004\n",
      "Epoch: 74 / Loss: 0.288551926612854\n",
      "Epoch: 75 / Loss: 0.3088695704936981\n",
      "Epoch: 76 / Loss: 0.2856704592704773\n",
      "Epoch: 77 / Loss: 0.30588608980178833\n",
      "Epoch: 78 / Loss: 0.28255167603492737\n",
      "Epoch: 79 / Loss: 0.3032665550708771\n",
      "Epoch: 80 / Loss: 0.27973654866218567\n",
      "Epoch: 81 / Loss: 0.3000149428844452\n",
      "Epoch: 82 / Loss: 0.2764231562614441\n",
      "Epoch: 83 / Loss: 0.2971835434436798\n",
      "Epoch: 84 / Loss: 0.27349960803985596\n",
      "Epoch: 85 / Loss: 0.29391878843307495\n",
      "Epoch: 86 / Loss: 0.27049893140792847\n",
      "Epoch: 87 / Loss: 0.29140931367874146\n",
      "Epoch: 88 / Loss: 0.2678242623806\n",
      "Epoch: 89 / Loss: 0.28872302174568176\n",
      "Epoch: 90 / Loss: 0.26530158519744873\n",
      "Epoch: 91 / Loss: 0.28696173429489136\n",
      "Epoch: 92 / Loss: 0.26358023285865784\n",
      "Epoch: 93 / Loss: 0.28516069054603577\n",
      "Epoch: 94 / Loss: 0.26135531067848206\n",
      "Epoch: 95 / Loss: 0.2833719551563263\n",
      "Epoch: 96 / Loss: 0.25931090116500854\n",
      "Epoch: 97 / Loss: 0.28120437264442444\n",
      "Epoch: 98 / Loss: 0.2570975124835968\n",
      "Epoch: 99 / Loss: 0.2787899971008301\n"
     ]
    }
   ],
   "source": [
    "model = MLP(100)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "train(model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834a1729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / Loss: 1.2795909643173218\n",
      "Epoch: 1 / Loss: 31.23565101623535\n",
      "Epoch: 2 / Loss: 84.49176788330078\n",
      "Epoch: 3 / Loss: 49.76136779785156\n",
      "Epoch: 4 / Loss: 16.48902130126953\n",
      "Epoch: 5 / Loss: 8.740314483642578\n",
      "Epoch: 6 / Loss: 3.6522057056427\n",
      "Epoch: 7 / Loss: 3.1241517066955566\n",
      "Epoch: 8 / Loss: 4.183623790740967\n",
      "Epoch: 9 / Loss: 0.330111026763916\n",
      "Epoch: 10 / Loss: 1.3803461790084839\n",
      "Epoch: 11 / Loss: 1.572358250617981\n",
      "Epoch: 12 / Loss: 2.1460726261138916\n",
      "Epoch: 13 / Loss: 0.23500877618789673\n",
      "Epoch: 14 / Loss: 0.23027311265468597\n",
      "Epoch: 15 / Loss: 0.1191815435886383\n",
      "Epoch: 16 / Loss: 0.10627786070108414\n",
      "Epoch: 17 / Loss: 0.0909871980547905\n",
      "Epoch: 18 / Loss: 0.08743362128734589\n",
      "Epoch: 19 / Loss: 0.08489298820495605\n",
      "Epoch: 20 / Loss: 0.08361998945474625\n",
      "Epoch: 21 / Loss: 0.08266277611255646\n",
      "Epoch: 22 / Loss: 0.08192596584558487\n",
      "Epoch: 23 / Loss: 0.08128473907709122\n",
      "Epoch: 24 / Loss: 0.08070994913578033\n",
      "Epoch: 25 / Loss: 0.08018054068088531\n",
      "Epoch: 26 / Loss: 0.07968815416097641\n",
      "Epoch: 27 / Loss: 0.07922499626874924\n",
      "Epoch: 28 / Loss: 0.07878734916448593\n",
      "Epoch: 29 / Loss: 0.07837020605802536\n",
      "Epoch: 30 / Loss: 0.07797221839427948\n",
      "Epoch: 31 / Loss: 0.07759030908346176\n",
      "Epoch: 32 / Loss: 0.07722336798906326\n",
      "Epoch: 33 / Loss: 0.07687050104141235\n",
      "Epoch: 34 / Loss: 0.07653066515922546\n",
      "Epoch: 35 / Loss: 0.07620184868574142\n",
      "Epoch: 36 / Loss: 0.0758833959698677\n",
      "Epoch: 37 / Loss: 0.07557640969753265\n",
      "Epoch: 38 / Loss: 0.07527953386306763\n",
      "Epoch: 39 / Loss: 0.07498951256275177\n",
      "Epoch: 40 / Loss: 0.07470585405826569\n",
      "Epoch: 41 / Loss: 0.07443107664585114\n",
      "Epoch: 42 / Loss: 0.07416457682847977\n",
      "Epoch: 43 / Loss: 0.07390526682138443\n",
      "Epoch: 44 / Loss: 0.07365228235721588\n",
      "Epoch: 45 / Loss: 0.07340632379055023\n",
      "Epoch: 46 / Loss: 0.07316609472036362\n",
      "Epoch: 47 / Loss: 0.07293164730072021\n",
      "Epoch: 48 / Loss: 0.07270359992980957\n",
      "Epoch: 49 / Loss: 0.07248087227344513\n",
      "Epoch: 50 / Loss: 0.07226304709911346\n",
      "Epoch: 51 / Loss: 0.0720498114824295\n",
      "Epoch: 52 / Loss: 0.07184109091758728\n",
      "Epoch: 53 / Loss: 0.0716366097331047\n",
      "Epoch: 54 / Loss: 0.07143551856279373\n",
      "Epoch: 55 / Loss: 0.0712379738688469\n",
      "Epoch: 56 / Loss: 0.07104415446519852\n",
      "Epoch: 57 / Loss: 0.07085368782281876\n",
      "Epoch: 58 / Loss: 0.07066638022661209\n",
      "Epoch: 59 / Loss: 0.07048206031322479\n",
      "Epoch: 60 / Loss: 0.0703016147017479\n",
      "Epoch: 61 / Loss: 0.07012462615966797\n",
      "Epoch: 62 / Loss: 0.0699504017829895\n",
      "Epoch: 63 / Loss: 0.06977668404579163\n",
      "Epoch: 64 / Loss: 0.06960592418909073\n",
      "Epoch: 65 / Loss: 0.0694383904337883\n",
      "Epoch: 66 / Loss: 0.06927402317523956\n",
      "Epoch: 67 / Loss: 0.06911249458789825\n",
      "Epoch: 68 / Loss: 0.06895334273576736\n",
      "Epoch: 69 / Loss: 0.06879527866840363\n",
      "Epoch: 70 / Loss: 0.06864087283611298\n",
      "Epoch: 71 / Loss: 0.06849123537540436\n",
      "Epoch: 72 / Loss: 0.06834480166435242\n",
      "Epoch: 73 / Loss: 0.0682012215256691\n",
      "Epoch: 74 / Loss: 0.06805946677923203\n",
      "Epoch: 75 / Loss: 0.06791961938142776\n",
      "Epoch: 76 / Loss: 0.0677821934223175\n",
      "Epoch: 77 / Loss: 0.06764696538448334\n",
      "Epoch: 78 / Loss: 0.06751379370689392\n",
      "Epoch: 79 / Loss: 0.06738168746232986\n",
      "Epoch: 80 / Loss: 0.06725170463323593\n",
      "Epoch: 81 / Loss: 0.06712401658296585\n",
      "Epoch: 82 / Loss: 0.06699755042791367\n",
      "Epoch: 83 / Loss: 0.06687258183956146\n",
      "Epoch: 84 / Loss: 0.06674928218126297\n",
      "Epoch: 85 / Loss: 0.06662721931934357\n",
      "Epoch: 86 / Loss: 0.06650609523057938\n",
      "Epoch: 87 / Loss: 0.06638684868812561\n",
      "Epoch: 88 / Loss: 0.06626930832862854\n",
      "Epoch: 89 / Loss: 0.0661536157131195\n",
      "Epoch: 90 / Loss: 0.06603938341140747\n",
      "Epoch: 91 / Loss: 0.06592616438865662\n",
      "Epoch: 92 / Loss: 0.06581443548202515\n",
      "Epoch: 93 / Loss: 0.06570452451705933\n",
      "Epoch: 94 / Loss: 0.06559567898511887\n",
      "Epoch: 95 / Loss: 0.06548850983381271\n",
      "Epoch: 96 / Loss: 0.06538253277540207\n",
      "Epoch: 97 / Loss: 0.06527791917324066\n",
      "Epoch: 98 / Loss: 0.06517455726861954\n",
      "Epoch: 99 / Loss: 0.06507252901792526\n"
     ]
    }
   ],
   "source": [
    "model = MLP(1000)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "train(model, optimizer, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
